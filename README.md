# RVBench

**RVBench** is a benchmark framework for evaluating **hybrid queries** in vector databases using a MediaWiki-based dataset. It integrates structured and vector data to assess performance on real-world hybrid workloads.

## Requirements

- **FAISS** (libfaiss.a) and OpenBLAS
- **HNSWlib** for C++
- **C++17** with OpenMP support
- **Python 3.6+**
- **HuggingFace transformers** (for benchmark_generator.py)

## Project Structure

The repository is organized into five main directories:

```
RVBench/
â”œâ”€â”€ baseline-implementation/
â”œâ”€â”€ database-generation/
â”œâ”€â”€ output-files/
â”œâ”€â”€ query-generation/
â””â”€â”€ query-templates/
```

### 1. database-generation/

This directory contains all components for generating the benchmark database and embeddings.

#### Subdirectories:

- **`data_csv_files/`** - Contains the core MediaWiki dataset files organized in subdirectories:
  - `category_csv_files/` - Contains `category_links_clean.csv` with columns `cl_from` and `cl_to`
  - `page_csv_files/` - Contains:
    - `page.csv` - Columns: `page_id`, `page_title` (ordered by page_id)
    - `embedding.csv` - Embeddings corresponding to page titles in same order as page.csv
    - `page_extra.csv` - Columns: `page_len`, `page_touched`, `page_namespace` (ordered by page_id)
  - `text_csv_files/` - Contains:
    - `text.csv` - Columns: `old_id`, `old_text` (ordered by old_id)
    - `embedding.csv` - Embeddings for old_text in same order as text.csv
  - `revision_csv_files/` - Contains `revision_clean.csv` with columns: `rev_id`, `rev_page`, `rev_minor_edit`, `rev_actor`, `rev_timestamp`

- **`index_files/`** - C++ implementation files to generate indexes using HNSWlib and FAISS libraries

- **`offsets_files/`** - Code to generate offset files for fast line access in baseline implementation

#### Quick Start:

```bash
cd database-generation
bash database_and_query_generator.sh
```

This script will:
- Generate all embedding files (for page and text)
- Create queries in the query-generation directory
- Build required index and offset files

#### Customization:

- **Embedding Models**: Check `models_supported.txt` for available models. Modify the first command in `database_and_query_generator.sh` to use a different model (instructions provided in comments inside the sh file)
- **System Configuration**: Update FAISS library paths in compile commands according to your system setup (further instructions in sh file)

## Sampling 

To sample the dataset of smaller size from original mediawiki dataset:

```bash
cd database-generation
python3 sampling.py <rows_in_page_table>
```

Where the user need to give number of rows needed in the final dataset inside the page table as command line argument, and the new dataset will be created from the original one having that number of rows in page table. Note:- Number of rows must be less than what it is in original page.csv file.

### 2. baseline-implementation/

Contains the C++ baseline implementation for query execution.

#### Structure:
- **`queries/`** - C++ implementation of all 39 benchmark queries
  - `runner.cpp` - Main query execution runner
  - `run.sh` - Compilation and execution script

#### Usage:

```bash
cd baseline-implementation/queries
bash run.sh
```

This will compile and run all queries for all combinations of indexes and metrics, outputting query execution times.

**Note**: Update FAISS library paths in `run.sh` according to your system configuration. (further instructions in sh file's comments)

#### Additional Files:
- `pipeline_stages.cpp` - Helper implementations for indexes and utility functions

### 3. query-generation/

Contains generated queries for each of the 39 benchmark queries in the format required by the baseline implementation. These are automatically generated by the database generation script.

### 4. query-templates/

Contains SQL templates for all 39 queries organized by similarity semantic categories:
- Nearest neighbor queries
- Interval-based queries  
- Sampling-based queries

### 5. output-files/

Contains experimental results and analysis tools.

#### Contents:
- **Results directories**:
  - `brute_queries_output/` - Brute force query results
  - `baseline_queries_output/` - Baseline implementation results
  - `pgvector_query_plans/` - PostgreSQL pgvector execution plans
  - `postgres_queries_output/` - PostgreSQL pgvector query results

- **Analysis tools**:
  - `ground_truth_result_computer.py` - Python script for running queries using pgvector with psycopg2 to compute ground truth results
  - `accuracy_baseline.sh` - Accuracy calculation script for baseline implementation
  - `raw_results.xlsx` - Raw experimental results with color-coded performance comparisons

**Note on Ground Truth**: Ground truth is calculated using PostgreSQL with pgvector. The current directories already contain ground truth results for the default experimental setup. However, if you use a different embedding model, you will need to recalculate the ground truth using `ground_truth_result_computer.py`, which requires PostgreSQL and pgvector to be installed and configured on your system. The existing results are provided for the experimented dataset and default embedding model.

#### Accuracy Evaluation:

```bash
cd output-files
bash accuracy_baseline.sh
```

This script calculates accuracy results for all combinations of metrics and indexes for the baseline implementation.

#### Result Interpretation:
The Excel sheet uses color coding:
- ðŸ”´ **Red**: pgvector outperforms baseline
- ðŸ”µ **Blue**: Similar performance
- ðŸŸ¢ **Green**: Baseline outperforms pgvector

## Getting Started

1. **Prepare your MediaWiki dataset** in the required CSV format within `data_csv_files/`
2. **Configure system paths** for FAISS library locations
3. **Generate database and queries**:
   ```bash
   cd database-generation
   bash database_and_query_generator.sh
   ```
4. **Run baseline benchmarks**:
   ```bash
   cd baseline-implementation/queries
   bash run.sh
   ```
5. **Evaluate accuracy**:
   ```bash
   cd output-files
   bash accuracy_baseline.sh
   ```
